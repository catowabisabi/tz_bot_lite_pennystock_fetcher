import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import json
from bson import json_util
import requests
import datetime
from datetime import  timezone, timedelta
from bs4 import BeautifulSoup
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv(override=True)




# region Summarizer====
class Summarizer:
    def __init__(self):
        self.key= os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=self.key)

    #region GPT Summarizer
    def summarize(self, text: str) -> str:
        prompt = f"è«‹æ ¹æ“šä»¥ä¸‹æ–°èå…§å®¹ç”Ÿæˆç¹é«”ä¸­æ–‡ç°¡çŸ­æ‘˜è¦ï¼š\n\n{str(text)}"
        completion = self.client.chat.completions.create(
        model="gpt-4.1",
        messages=[
            {"role": "developer", "content": "You are a helpful assistant. You take news content as input and generate a detailed summary. Do not include the original news content in the summary."},
            {"role": "user", "content": prompt}
        ]
        )
        summary = completion.choices[0].message.content.strip()
        print(f"\nğŸ“° Summary: {summary}\n")
        return summary
    

    #region GPT suggestion
    def suggestion(self, text: str) -> str:
        prompt = f"è«‹æ ¹æ“šä»¥ä¸‹æ–°èå…§å®¹ç”Ÿæˆç°¡çŸ­å»ºè­°ï¼š\n\n{str(text)}"
        completion = self.client.chat.completions.create(
        model="gpt-4.1",
        messages=[
            {"role": "developer", "content": "ç”¨æˆ¶æ˜¯ä¸€å€‹æ—¥å…§äº¤æ˜“è€…, ä»–ä¸»è¦çš„æ˜¯åšç©ºè‚¡ç¥¨çš„äº¤æ˜“è€…, ç”¨æˆ¶æœƒæä¾›æœ€æ–°çš„æ–°èçš„ä¸€äº›ç¸½çµ, å¦‚æœæ–°èä¸­æœ‰éå¸¸å¼·çš„æ­£é¢æƒ…ç·’, è«‹å‘ç”¨æˆ¶åˆ—å‡ºé¢¨éšª, è§£é‡‹ç‚ºä½•ä¸å»ºè­°åšç©º, ä½†å¦‚æœæ²’æœ‰ç•¶å¤©çš„æ–°è, æˆ–æ–°èä¸­çš„æ­£é¢æƒ…ç·’ä¸é«˜, è«‹å‘ç”¨æˆ¶åˆ—å‡ºå»ºè­°ã€‚"},
            {"role": "user", "content": prompt}
        ]
        )
        summary = completion.choices[0].message.content.strip()
        #print(summary)
        return summary



#region RVLNewsAnalyzer====
class RVLNewsAnalyzer:
    def __init__(self):
        self.now = datetime.datetime.now(datetime.timezone.utc)
        self.yesterday = self.now - timedelta(days=2)
        self.summerizer = Summarizer()


    #region Is Recent News
    def is_recent(self, timestamp):
        try:
            news_time = datetime.datetime.fromtimestamp(timestamp, tz=datetime.timezone.utc)
            return news_time.date() in {self.now.date(), self.yesterday.date()}
        except Exception as e:
            print("âš ï¸ Timestamp error:", e)
            return False


    #region Clean HTML
    def clean_html(self, text):
        if text.startswith("http"):  # å‡è¨­å‚³é€²ä¾†çš„æ˜¯ URL
            try:
                response = requests.get(text)
                response.raise_for_status()
                html_content = response.text
                return BeautifulSoup(html_content, "html.parser").get_text()
            except requests.exceptions.RequestException as e:
                print(f"âŒ Failed to fetch URL: {e}")
                return ""
        else:
            return BeautifulSoup(text or "", "html.parser").get_text()

    #region News Analyzer 
    def analyze(self, news_data: list):
        recent_news = []
        for news in news_data:
            
            if not self.is_recent(news.get("utcTime")):
                #print(f"âš ï¸ Skipping non-recent news: ä¸æ˜¯æœ€è¿‘çš„æ–°è: {datetime.datetime.fromtimestamp(news['utcTime'], tz=datetime.timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')} - {news['title']}")
                continue

            news_time = datetime.datetime.fromtimestamp(news["utcTime"])
            readable_time = news_time.strftime('%Y-%m-%d %H:%M:%S UTC')

            
            
            entry = {
                "title": self.clean_html(news.get("title", "")),
                "time": readable_time,
                "link": news.get("link", ""),
                "html": self.clean_html(news.get("link", ""))
            }

            summary = self.summerizer.summarize(entry)

            entry = {
                "title": self.clean_html(news.get("title", "")),
                "time": readable_time,
                "link": news.get("link", ""),
                "summary": summary
            }

            recent_news.append(entry)



        # ä¾æ™‚é–“æ’åºï¼Œå–æœ€æ–°çš„ 5 å‰‡
        recent_news = sorted(recent_news, key=lambda x: x["time"], reverse=True)[:5]

        #print(json.dumps(recent_news, indent=2, ensure_ascii=False))
        return recent_news



#region TZ NewsFetcher====
class NewsFetcher:
    def __init__(self):
        

        from tz_api.api_auth import TzAuth
        self.tz_auth = TzAuth()
        self.jwt_token = self.tz_auth.jwt_token

        self.news_analyzer = RVLNewsAnalyzer()
        self.summerizer = Summarizer()

        self.base_url = "https://api.tradezero.com/v1/news/api/news/get"


    def get_symbols_news_and_analyze(self, symbols: list[str], page: int = 1, num_results: int = 5):
        
        headers = {
            "Authorization": f"Bearer {self.jwt_token}",
            "Content-Type": "application/json"
        }
        suggestions = []
        for symbol in symbols:
            print("================================================")
            print(f"\n\n\nğŸ“° Fetching news...:{symbol}")
            params = {
                "Page": page,
                "Symbol": symbol.upper(),
                "Keyword": "",
                "NumOfResults": num_results
            }

            try:
                response = requests.get(self.base_url, headers=headers, params=params)
                response.raise_for_status()
                # å–å¾— JSON ä¸­çš„æ–°èé™£åˆ—
                all_news = response.json()

                # éæ¿¾åªåŒ…å«é€™å€‹ symbol çš„æ–°è
                filtered_news = [
                    news for news in all_news
                    if news.get("symbols") == [symbol.upper()]
                ]

                data = filtered_news
                #print(json.dumps(data, indent=2, ensure_ascii=False))

                summaries = self.news_analyzer.analyze(data)
                print(f"\n\n ğŸ“° Summaries for {symbol.upper()}: {json.dumps(summaries, indent=2, ensure_ascii=False)}")

                suggestion = self.summerizer.suggestion(summaries)
                print(f"\n\n ğŸ“° Suggestion for {symbol.upper()}: {suggestion}")
    
                suggestions.append({"symbol": symbol, "suggestion": 	suggestion})
        
                
                
                #=================================================not printing the news, we need the suggestion only
                #print(f"\nğŸ“° News for {symbol.upper()}:")
                if data and isinstance(data, list):
                    for news in data[:num_results]:
                        
                        title = news.get("title", "No title")
                        link = news.get("link", "")
                        publisher = news.get("publisher", "Unknown publisher")
                        timestamp = news.get("utcTime")
                        if timestamp:
                            dt = datetime.datetime.fromtimestamp(timestamp, datetime.UTC).strftime('%Y-%m-%d %H:%M:%S UTC')
                        else:
                            dt = "Unknown time"

                        #print(f"- {title}\n  ğŸ“… {dt} | ğŸ—ï¸ {publisher}\n  ğŸ”— {link}\n")
                else:
                    pass
                    #print("âš ï¸ No news data available.")
                #=================================================================================
            
            except requests.exceptions.RequestException as e:
                print(f"âŒ Failed to fetch news for {symbol.upper()}: {e}")
                if hasattr(e, "response") and e.response:
                    print("Status Code:", e.response.status_code)
                    print("Response:", e.response.text)


        return suggestions

            
    
    def analyze_news(self, news_data):
        try:
            print("\nğŸ“° Analyzing news...")
            analyzed_news = self.news_analyzer.analyze(news_data)
            
            print(json_util.dumps(analyzed_news, indent=2, ensure_ascii=False))
            return analyzed_news
        except Exception as e:
            print(f"âŒ Failed to analyze news: {e}")
      


#region MAIN ENTRY
if __name__ == "__main__":
    fetcher = NewsFetcher()
    suggestions = fetcher.get_symbols_news_and_analyze(["AAPL", "MSFT"])

    #fake_news_data = {'publisherId': 45154555, 'keywords': ['NEWS', 'PRICE TARGET', 'ANALYST RATINGS'], 'symbols': ['MSFT'], 'utcTime': 1746136689, 'id': 6773239, 'title': 'Jefferies Maintains Buy on Microsoft, Raises Price Target to $550', 'link': 'https://www.benzinga.com/news/25/05/45154555/jefferies-maintains-buy-on-microsoft-raises-price-target-to-550', 'publisher': 'Benzinga Newsdesk', 'newsType': 'Headline', 'timing': 'None', 'msgType': 'NM_SYSMSG', 'symbolCode': 0, 'body': None}


   #news_analyzer = RVLNewsAnalyzer()
   # news_analyzer.analyze([fake_news_data])