import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from data_handler.merge_data import DataMerge
from data_handler.short_squeeze_scanner2 import ShortSqueezeScanner

from api_tradezero.api_stock_fundamental import FundamentalsFetcher
from api_tradezero.api_news_fetcher import NewsFetcher
from api_tradezero.api_chart import ChartAnalyzer

from get_sec_filings.get_sec_filings_5_demo import SECFinancialAnalyzer

from database._mongodb.mongo_handler import MongoHandler

from zoneinfo import ZoneInfo
from program_starter.class_zeropro_starter import logger
from datetime import datetime, timedelta

import time


ny_today = datetime.now(ZoneInfo("America/New_York")).strftime('%Y-%m-%d')


class SymbolMerger:
    def __init__(self, all_keys):
        self.all_keys = all_keys
        
    def merge(self, list_of_symbols, fundamentals, price_results):
        # Create mappings from symbols to their respective data
        symbol_map_fundamentals = {item['symbol']: item for item in fundamentals if item.get('symbol')}
        symbol_map_prices = {item['symbol']: item for item in price_results if item.get('symbol')}

        merged_results = []
        for symbol in list_of_symbols:
            record = {key: None for key in self.all_keys}
            record['symbol'] = symbol

            if symbol in symbol_map_fundamentals:
                record.update(symbol_map_fundamentals[symbol])
            if symbol in symbol_map_prices:
                record.update(symbol_map_prices[symbol])

            merged_results.append(record)

        return merged_results


class DataHandler:
    """
    èª¿è©¦ç‰ˆæœ¬çš„ DataHandler - æ·»åŠ è©³ç´°æ—¥èªŒä»¥æ‰¾å‡ºä¿å­˜å•é¡Œ
    """
    
    def __init__(self):
        self.fundamentals_fetcher = FundamentalsFetcher()
        self.mongo_handler = MongoHandler()
        self.mongo_handler.create_collection('fundamentals_of_top_list_symbols')
        self.news_fetcher = NewsFetcher()
        self.squeeze_scanner = ShortSqueezeScanner()
        
        # æ•¸æ“šå­˜å„²å±¬æ€§
        self.fundamentals = []
        self.list_of_symbols = []
        self._db_cache = {}

    def _get_db_documents(self, symbols=None, force_refresh=False):
        """çµ±ä¸€çš„æ•¸æ“šåº«æ–‡æª”ç²å–æ–¹æ³•ï¼Œå¸¶ç·©å­˜æ©Ÿåˆ¶"""
        if symbols is None:
            symbols = self.list_of_symbols
            
        cache_key = f"{'-'.join(sorted(symbols))}_{ny_today}"
        
        if not force_refresh and cache_key in self._db_cache:
            logger.info(f"Using cached data for {len(symbols)} symbols")
            return self._db_cache[cache_key]
        
        logger.info(f"Querying database for {len(symbols)} symbols on {ny_today}")
        documents = self.mongo_handler.find_doc(
            "fundamentals_of_top_list_symbols",
            {
                "symbol": {"$in": symbols},
                "today_date": ny_today
            }
        )
        
        logger.info(f"Found {len(documents)} documents in database")
        self._db_cache[cache_key] = documents
        return documents

    def check_merge_errors(self):
        """æª¢æŸ¥åˆä½µéŒ¯èª¤"""
        error_data = self.mongo_handler.find_doc(
            "fundamentals_of_top_list_symbols",
            {"close_change_percentage": {"$exists": False}}
        )
        print(f"Length of error data: {len(error_data)}")
        if len(error_data) > 0:
            logger.warning(f"Error: å·²æ‰¾åˆ° {len(error_data)} å€‹éŒ¯èª¤: Symbols: {error_data[0]['symbol']}")
            logger.warning(f"Error in fundamental data for symbol: {error_data[0]['symbol']}")
            logger.warning(f"é€€å‡ºç¨‹å¼")
            exit()
        logger.info(f"No errors in fundamental data")
        return False

    def get_fundamentals(self, symbol):
        """Get fundamental data for a single symbol."""
        return self.fundamentals_fetcher.fetch(symbol)
    
    def get_list_of_fundamentals(self, list_of_symbols):
        """Get fundamental data for multiple symbols."""
        return self.fundamentals_fetcher.fetch_symbols(list_of_symbols)

    def get_analyzer_data(self, symbol):
        """Get chart analysis data for a single symbol."""
        print(f"\n\n====================Getting chart data for symbol: {symbol}====================")  
        analyzer = ChartAnalyzer(symbol)
        result = analyzer.run()
        return result

    def get_price_analyzer_results(self, list_of_symbols):
        """Get price analysis results for multiple symbols."""
        price_analyzer_results = []
        for symbol in list_of_symbols:
            result = self.get_analyzer_data(symbol)
            price_analyzer_results.append(result)
        return price_analyzer_results

    def merge_fundamentals_and_price_data(self, list_of_symbols, fundamentals, price_analyzer_results):
        """Merge fundamental data with price analysis data."""
        # Define all possible fields
        all_keys = [
            'symbol', 'name', 'listingExchange', 'securityType', 'countryDomicile', 'countryIncorporation',
            'isin', 'sector', 'industry', 'lastSplitInfo', 'lastSplitDate', 'lotSize', 'optionable',
            'earningsPerShare', 'earningsPerShareTTM', 'forwardEarningsPerShare', 'nextEarnings',
            'annualDividend', 'last12MonthDividend', 'lastDividend', 'exDividend', 'dividendFrequency',
            'beta', 'averageVolume3M', 'turnoverPercentage', 'bookValue', 'sales', 'outstandingShares', 'float',
            # Add price fields
            'premarket_high', 'premarket_low', 'market_open_high', 'market_open_low', 'day_high', 'day_low',
            'day_close', 'yesterday_close', 'high_change_percentage', 'close_change_percentage',
            'most_volume_high', 'most_volume_low'
        ]

        merger = SymbolMerger(all_keys)
        return merger.merge(list_of_symbols, fundamentals, price_analyzer_results)

    def perform_short_squeeze_analysis(self):
        """Perform short squeeze analysis on fundamental data."""
        logger.info("Starting Short Squeeze Analysis")
        list_of_short_squeeze_results = []
        
        for fundamental in self.fundamentals:
            short_squeeze_results = self.squeeze_scanner.run(
                new_stock_data=fundamental,
                current_price=fundamental['day_close'],
                intraday_high=fundamental['day_high'],
                short_interest=None,
                as_json=True
            )
            list_of_short_squeeze_results.append(short_squeeze_results)
            logger.info(f"Short Squeeze Analysis for {fundamental['symbol']} Ready!")
            #self.squeeze_scanner.print_readable_analysis()

        logger.info(f"Short Squeeze Analysis Lengths: {len(list_of_short_squeeze_results)}")
        
        # å„ªåŒ–çš„åˆä½µæ–¹æ³•ï¼šç›´æ¥å­—å…¸æ›´æ–°
        squeeze_results_map = {item['symbol']: item for item in list_of_short_squeeze_results if item.get('symbol')}
        
        for fundamental_item in self.fundamentals:
            symbol = fundamental_item.get('symbol')
            if symbol and symbol in squeeze_results_map:
                # ç›´æ¥æ›´æ–°ç¾æœ‰çš„ fundamental å­—å…¸ï¼Œé¿å…è¦†è“‹é‡è¦å­—æ®µ
                squeeze_data = squeeze_results_map[symbol].copy()
                squeeze_data.pop('symbol', None)  # ç§»é™¤ symbol éµé¿å…é‡è¤‡
                fundamental_item.update(squeeze_data)
                logger.info(f"Short Squeeze Analysis Merged into Fundamentals for {symbol} !")
        
        logger.info(f"Successfully merged short squeeze analysis for {len(squeeze_results_map)} symbols")
        return self.fundamentals

    def handle_symbols(self, list_of_symbols):
        """Process symbols to get fundamentals, price data, and short squeeze analysis."""
        logger.info(f"è™•ç† {len(list_of_symbols)} å€‹ç¬¦è™Ÿçš„æ•¸æ“š")
        
        # Get price analysis results
        price_analyzer_results = self.get_price_analyzer_results(list_of_symbols)
        logger.info(f"ç²å–åˆ° {len(price_analyzer_results)} å€‹åƒ¹æ ¼åˆ†æçµæœ")
        
        # Get fundamental data
        fundamentals = self.get_list_of_fundamentals(list_of_symbols)
        logger.info(f"ç²å–åˆ° {len(fundamentals)} å€‹åŸºæœ¬é¢æ•¸æ“š")
        
        # Merge fundamental and price data
        self.fundamentals = self.merge_fundamentals_and_price_data(list_of_symbols, fundamentals, price_analyzer_results)
        logger.info(f"åˆä½µå¾Œçš„åŸºæœ¬é¢æ•¸æ“šé•·åº¦: {len(self.fundamentals)}")
        
        # æª¢æŸ¥åˆä½µå¾Œæ•¸æ“šçš„çµæ§‹
        if self.fundamentals:
            sample_keys = list(self.fundamentals[0].keys())
            logger.info(f"æ¨£æœ¬æ•¸æ“šå­—æ®µ: {sample_keys[:10]}...")  # åªé¡¯ç¤ºå‰10å€‹å­—æ®µ
        
        # Perform short squeeze analysis
        return self.perform_short_squeeze_analysis() #return fundamentals with short squeeze analysis

    def store_fundamentals_in_db(self):
        """Store or update fundamental data in MongoDB - æ·»åŠ è©³ç´°èª¿è©¦ä¿¡æ¯"""
        logger.info(f"é–‹å§‹ä¿å­˜ {len(self.fundamentals)} å€‹åŸºæœ¬é¢æ•¸æ“šåˆ°æ•¸æ“šåº«")
        
        # æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
        for i, fundamental in enumerate(self.fundamentals):
            if not fundamental.get('symbol'):
                logger.error(f"ç¬¬ {i} å€‹åŸºæœ¬é¢æ•¸æ“šç¼ºå°‘ symbol å­—æ®µ: {fundamental}")
                continue
            
            # æª¢æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„åƒ¹æ ¼æ•¸æ“š
            required_fields = ['day_close', 'close_change_percentage']
            missing_fields = [field for field in required_fields if field not in fundamental or fundamental[field] is None]
            if missing_fields:
                logger.warning(f"Symbol {fundamental['symbol']} ç¼ºå°‘å­—æ®µ: {missing_fields}")
        
        ny_time = datetime.now(ZoneInfo("America/New_York"))
        ny_today = ny_time.strftime('%Y-%m-%d')
        date_list = [(ny_time - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(7)]
        
        logger.info(f"æŸ¥è©¢æœ€è¿‘ 7 å¤©çš„æ•¸æ“š: {date_list}")

        # Query recent fundamental documents
        recent_fundamental_docs = self.mongo_handler.find_doc(
            "fundamentals_of_top_list_symbols",
            {
                "symbol": {"$in": [f["symbol"] for f in self.fundamentals]},
                "today_date": {"$in": date_list}
            }
        )
        
        logger.info(f"æ‰¾åˆ° {len(recent_fundamental_docs)} å€‹æœ€è¿‘çš„åŸºæœ¬é¢æ–‡æª”")
        recent_symbols = set(doc["symbol"] for doc in recent_fundamental_docs)
        
        # ä¿å­˜è¨ˆæ•¸å™¨
        saved_count = 0
        updated_count = 0

        for fundamental in self.fundamentals:
            symbol = fundamental["symbol"]
            fundamental["today_date"] = ny_today

            # å–å‡ºé€™å€‹ symbol æœ€è¿‘ 7 å¤©çš„èˆŠè³‡æ–™
            recent_docs = [doc for doc in recent_fundamental_docs if doc["symbol"] == symbol]
            
            if recent_docs:
                # æ‰¾åˆ°æœ€æ–°çš„é‚£ç­†ï¼ˆè‹¥æœ‰å¤šç­†ï¼‰
                latest_doc = max(recent_docs, key=lambda d: d["today_date"])

                # ä¿ç•™èˆŠè³‡æ–™ä¸­å…¶ä»–å­—æ®µï¼Œæ›´æ–°ç‚ºæ–°è³‡æ–™ï¼ˆæ–°è³‡æ–™å„ªå…ˆï¼‰
                merged_data = {**latest_doc, **fundamental}
                merged_data["today_date"] = ny_today  # ä¸€å®šæ˜¯ä»Šå¤©

                try:
                    result = self.mongo_handler.upsert_doc(
                        "fundamentals_of_top_list_symbols",
                        {"symbol": symbol, "today_date": ny_today},
                        merged_data
                    )
                    logger.info(f"æ›´æ–° {symbol}ï¼šåˆä½µèˆŠè³‡æ–™å¾Œä¿å­˜ç‚ºä»Šå¤©çš„è³‡æ–™")
                    updated_count += 1
                except Exception as e:
                    logger.error(f"æ›´æ–° {symbol} æ™‚å‡ºéŒ¯: {e}")
            else:
                # æ²’æœ‰èˆŠè³‡æ–™ï¼Œç›´æ¥æ’å…¥ä»Šå¤©çš„è³‡æ–™
                try:
                    result = self.mongo_handler.upsert_doc(
                        "fundamentals_of_top_list_symbols",
                        {"symbol": symbol, "today_date": ny_today},
                        fundamental
                    )
                    logger.info(f"æ–°å¢ {symbol} ç‚ºä»Šå¤©çš„æ–°è³‡æ–™")
                    saved_count += 1
                except Exception as e:
                    logger.error(f"å„²å­˜ {symbol} æ™‚å‡ºéŒ¯: {e}")

        
        # é©—è­‰ä¿å­˜çµæœ
        time.sleep(1)
        verification_docs = self.mongo_handler.find_doc(
            "fundamentals_of_top_list_symbols",
            {
                "symbol": {"$in": [f["symbol"] for f in self.fundamentals]},
                "today_date": ny_today
            }
        )
        logger.info(f"é©—è­‰: æ•¸æ“šåº«ä¸­æ‰¾åˆ° {len(verification_docs)} å€‹ä»Šæ—¥æ–‡æª”")
        
        # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰æ•¸æ“šéƒ½å·²ä¿å­˜
        saved_symbols = set(doc["symbol"] for doc in verification_docs)
        missing_symbols = set(f["symbol"] for f in self.fundamentals) - saved_symbols
        if missing_symbols:
            logger.error(f"ä»¥ä¸‹ç¬¦è™Ÿçš„æ•¸æ“šæœªèƒ½ä¿å­˜åˆ°æ•¸æ“šåº«: {missing_symbols}")
        else:
            logger.info("æ‰€æœ‰åŸºæœ¬é¢æ•¸æ“šå·²æˆåŠŸä¿å­˜åˆ°æ•¸æ“šåº«")

    def process_suggestions(self):
        """çµ±ä¸€è™•ç†å»ºè­°çš„æ–¹æ³•"""
        logger.info("Processing suggestions...")
        
        # ç²å–æ•¸æ“šåº«ä¸­å·²æœ‰å»ºè­°çš„æ–‡æª”
        documents = self._get_db_documents()
        existing_suggestions_symbols = {
            doc["symbol"] for doc in documents 
            if doc.get("suggestion")
        }
        
        logger.info(f"æ‰¾åˆ° {len(existing_suggestions_symbols)} å€‹å·²æœ‰å»ºè­°çš„ç¬¦è™Ÿ")
        
        # æ‰¾å‡ºéœ€è¦åˆ†æçš„æ–°ç¬¦è™Ÿ
        symbols_to_analyze = [
            symbol for symbol in self.list_of_symbols 
            if symbol not in existing_suggestions_symbols
        ]
        
        # ç‚ºæ–°ç¬¦è™Ÿç²å–AIåˆ†æ
        if symbols_to_analyze:
            logger.info(f"æ­£åœ¨ç‚º {len(symbols_to_analyze)} å€‹æ–°ç¬¦è™Ÿåˆ†æå»ºè­°")
            time.sleep(1)
            new_suggestions = self.news_fetcher.get_symbols_news_and_analyze(symbols_to_analyze)
            
            # ç›´æ¥æ›´æ–°åˆ°æ•¸æ“šåº«ï¼Œä¸ä¿å­˜å‰¯æœ¬
            for suggestion in new_suggestions:
                try:
                    result = self.mongo_handler.upsert_doc(
                        "fundamentals_of_top_list_symbols", 
                        {"symbol": suggestion["symbol"], "today_date": ny_today}, 
                        {"suggestion": suggestion["suggestion"]}
                    )
                    logger.info(f"ä¿å­˜å»ºè­° {suggestion['symbol']}: {result}")
                except Exception as e:
                    logger.error(f"ä¿å­˜å»ºè­° {suggestion['symbol']} æ™‚å‡ºéŒ¯: {e}")
            
            # åˆ·æ–°ç·©å­˜
            self._get_db_documents(force_refresh=True)
            
            # æ‰“å°æ–°å»ºè­°
            self.print_readable_suggestions(new_suggestions)
            
            return len(new_suggestions)
        
        logger.info("No new symbols need suggestion analysis")
        return 0

    def process_sec_analysis(self):
        """çµ±ä¸€è™•ç†SECåˆ†æçš„æ–¹æ³•"""
        logger.info("Processing SEC filing analysis...")
        
        # ç²å–å·²æœ‰SECåˆ†æçš„ç¬¦è™Ÿ
        documents = self._get_db_documents()
        analyzed_symbols = {
            doc["symbol"] for doc in documents 
            if doc.get("sec_filing_analysis")
        }
        
        logger.info(f"æ‰¾åˆ° {len(analyzed_symbols)} å€‹å·²æœ‰SECåˆ†æçš„ç¬¦è™Ÿ")
        
        # æ‰¾å‡ºéœ€è¦åˆ†æçš„ç¬¦è™Ÿ
        symbols_to_analyze = [
            symbol for symbol in self.list_of_symbols 
            if symbol not in analyzed_symbols
        ]
        
        if symbols_to_analyze:
            logger.info(f"æ­£åœ¨ç‚º {len(symbols_to_analyze)} å€‹ç¬¦è™Ÿåˆ†æSECæ–‡ä»¶")
            analyzer = SECFinancialAnalyzer()
            analyzer.SYMBOL_LIST = symbols_to_analyze
            analysis_results = analyzer.run_analysis()

            # ç›´æ¥æ›´æ–°åˆ°æ•¸æ“šåº«
            for analysis_result in analysis_results:
                symbol = analysis_result["Symbol"]
                try:
                    result = self.mongo_handler.upsert_doc(
                        "fundamentals_of_top_list_symbols",
                        {"symbol": symbol, "today_date": ny_today},
                        {"sec_filing_analysis": analysis_result}
                    )
                    logger.info(f"ä¿å­˜SECåˆ†æ {symbol}: {result}")
                except Exception as e:
                    logger.error(f"ä¿å­˜SECåˆ†æ {symbol} æ™‚å‡ºéŒ¯: {e}")
            
            # åˆ·æ–°ç·©å­˜
            self._get_db_documents(force_refresh=True)
            
            return len(analysis_results)
        
        logger.info("No new symbols need SEC analysis")
        return 0

    def build_final_results(self):
        """æ§‹å»ºæœ€çµ‚çµæœ"""
        logger.info("Building final results...")
        
        # ç²å–æ‰€æœ‰ä»Šæ—¥çš„åŸºæœ¬é¢æ–‡æª”
        documents = self._get_db_documents()
        
        # æ§‹å»ºæœ€çµ‚çµæœ
        final_fundamentals = []
        final_sec_analyses = []
        
        for doc in documents:
            # åŸºæœ¬é¢æ•¸æ“š
            final_fundamentals.append(doc)
            
            # SECåˆ†æçµæœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if "sec_filing_analysis" in doc:
                final_sec_analyses.append(doc["sec_filing_analysis"])
        
        logger.info(f"Final results: {len(final_fundamentals)} fundamentals, {len(final_sec_analyses)} SEC analyses")
        
        return final_fundamentals, final_sec_analyses

    def print_readable_suggestions(self, suggestions: list[dict]):
        """Print suggestions in a human-readable format."""
        for item in suggestions:
            symbol = item.get("symbol", "Unknown symbol")
            suggestion = item.get("suggestion", "(No suggestion content)")

            print("====================================")
            print(f"ğŸ“Œ Suggestion for {symbol}:\n\n")
            print(suggestion)
            print("\n")

    def get_positions(self):
        """Placeholder for retrieving current positions from trading account."""
        pass

    def get_accounts(self):
        """Placeholder for retrieving account information."""
        pass

    def run(self, list_of_symbols):
        """
        èª¿è©¦ç‰ˆæœ¬çš„ä¸»åŸ·è¡Œæ–¹æ³•
        """
        logger.info(f"=== é–‹å§‹é‹è¡Œ DataHandlerï¼Œè™•ç† {len(list_of_symbols)} å€‹ç¬¦è™Ÿ ===")
        logger.info(f"ç¬¦è™Ÿåˆ—è¡¨: {list_of_symbols}")
        
        self.list_of_symbols = list_of_symbols
        self._db_cache.clear()  # æ¸…ç©ºç·©å­˜
        
        # Step 1: è™•ç†ç¬¦è™Ÿä¸¦ç²å–åŸºæœ¬é¢æ•¸æ“šå’Œåˆ†æ
        logger.info("=== Step 1: è™•ç†ç¬¦è™Ÿå’ŒåŸºæœ¬é¢æ•¸æ“š ===")
        self.fundamentals = self.handle_symbols(self.list_of_symbols) #return fundamentals with short squeeze analysis
        
        if not self.fundamentals:
            logger.error("âŒ æ²’æœ‰ç²å–åˆ°ä»»ä½•åŸºæœ¬é¢æ•¸æ“šï¼")
            return [], []
        
        logger.info(f"âœ… æˆåŠŸè™•ç† {len(self.fundamentals)} å€‹åŸºæœ¬é¢æ•¸æ“š")
        
        # Step 2: å°‡åŸºæœ¬é¢æ•¸æ“šå­˜å„²åˆ°æ•¸æ“šåº«
        logger.info("=== Step 2: å­˜å„²åŸºæœ¬é¢æ•¸æ“šåˆ°æ•¸æ“šåº« ===")
        self.store_fundamentals_in_db()
        
        # Step 3: è™•ç†å»ºè­°
        logger.info("=== Step 3: è™•ç†å»ºè­° ===")
        new_suggestions_count = self.process_suggestions()
        
        # Step 4: è™•ç†SECåˆ†æ
        logger.info("=== Step 4: è™•ç†SECåˆ†æ ===")
        new_analyses_count = self.process_sec_analysis()
        
        # Step 5: æ§‹å»ºæœ€çµ‚çµæœ
        logger.info("=== Step 5: æ§‹å»ºæœ€çµ‚çµæœ ===")
        final_fundamentals, final_sec_analyses = self.build_final_results()
        
        # Step 6: æª¢æŸ¥åˆä½µéŒ¯èª¤
        logger.info("=== Step 6: æª¢æŸ¥åˆä½µéŒ¯èª¤ ===")
        self.check_merge_errors()
        
        logger.info(f"""
        === è™•ç†å®Œæˆï¼ ===
        - è™•ç†ç¬¦è™Ÿæ•¸é‡: {len(self.list_of_symbols)}
        - æ–°å»ºè­°æ•¸é‡: {new_suggestions_count}
        - æ–°SECåˆ†ææ•¸é‡: {new_analyses_count}
        - è¿”å›åŸºæœ¬é¢æ•¸æ“š: {len(final_fundamentals)}
        - è¿”å›SECåˆ†æ: {len(final_sec_analyses)}
        """)
        
        return final_fundamentals, final_sec_analyses